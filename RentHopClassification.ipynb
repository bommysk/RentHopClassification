{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- generating record_list: 0.18744802474975586 seconds ---\n",
      "Decision Tree 1.0\n",
      "Naive Bayes 0.985\n",
      "Random Forest 0.67\n",
      "Passive Aggressive Classifier 0.285\n",
      "K Nearest Neighbors Classifier 0.55\n",
      "SGD Classifier 0.64\n",
      "Perceptron 0.64\n",
      "Ridge Classifier 0.64\n",
      "Nearest Centroid 0.55\n",
      "BernoulliNB 0.37\n",
      "--- training/classification: 0.2437608242034912 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python3\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "from math import log\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import string\n",
    "import re\n",
    "import nltk.classify.decisiontree\n",
    "import nltk.classify.naivebayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import cmudict \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import time\n",
    "\n",
    "train_data = pd.read_json(\"/Users/shubhamkahal/Downloads/train.json\").head(200)\n",
    "\n",
    "# take out fields we don't need\n",
    "del train_data['created']\n",
    "del train_data['display_address']\n",
    "del train_data['latitude']\n",
    "del train_data['longitude']\n",
    "del train_data['photos']\n",
    "del train_data['street_address']\n",
    "\n",
    "#test_data = pd.read_json(\"/Users/shubhamkahal/Downloads/test.json\").head(200)\n",
    "\n",
    "class WordFeatures:\n",
    "    def __init__(self, min_cut=0.1, max_cut=0.9):\n",
    "        # class constructor - takes in min and max cutoffs for \n",
    "        # frequency\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + [u\"'s\",'\"'])\n",
    "\n",
    "    def clean_html(self, raw_html):\n",
    "        cleanr = re.compile('<.*?>')\n",
    "        cleantext = re.sub(cleanr, '', raw_html)\n",
    "        return cleantext\n",
    "\n",
    "    def is_number(self, s):\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def get_number_of_syllables(self, word):\n",
    "        if self.is_number(word):\n",
    "            return 1\n",
    "\n",
    "        d = cmudict.dict() \n",
    "\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "    \n",
    "word_features = WordFeatures()\n",
    "\n",
    "def get_price_bins(price_list, bin_num):\n",
    "    prices = []\n",
    "    bins = []\n",
    "\n",
    "    for price in price_list:\n",
    "        prices.append(int(price))\n",
    "\n",
    "    prices.sort()\n",
    "\n",
    "    bin_size = (len(prices) // bin_num)\n",
    "    counter_start = 0\n",
    "    counter_end = 1\n",
    "\n",
    "    while (counter_start < bin_num):\n",
    "        bins.append(prices[(counter_start * bin_size) : (counter_end * bin_size)])\n",
    "\n",
    "        counter_start += 1\n",
    "        counter_end += 1\n",
    "\n",
    "    return bins\n",
    "\n",
    "def bin_price(price, price_bins):\n",
    "    # price is gauranteed to be in a bin\n",
    "    for bin in price_bins:\n",
    "        if price >= bin[0] and price <= bin[-1]:\n",
    "            return sum(bin) / len(bin)\n",
    "\n",
    "def get_uppercase_lowercase_ratio(description):\n",
    "    if len(description) == 0:\n",
    "        return {\"uppercase_ratio\" : 0, \"lowercase_ratio\" : 0}\n",
    "\n",
    "    words = description.split(' ')\n",
    "    upper_count = 0\n",
    "    lower_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            if letter.isupper():\n",
    "                upper_count += 1\n",
    "            else:\n",
    "                lower_count += 1\n",
    "\n",
    "    return {\"uppercase_ratio\" : (upper_count / len(description)), \"lowercase_ratio\" : (lower_count / len(description))}\n",
    "\n",
    "def get_completeness_score(row, columns):\n",
    "    completeness_score = 0\n",
    "\n",
    "    for column in columns:\n",
    "        if isinstance(row[column], (int, float, complex)) or len(row[column]) > 0:\n",
    "            completeness_score += 1\n",
    "\n",
    "    return completeness_score\n",
    "\n",
    "def get_fog_index(description):\n",
    "    if (len(description) == 0):\n",
    "        return 0\n",
    "\n",
    "    sentences = sent_tokenize(description)\n",
    "    words = word_tokenize(description)\n",
    "    complex_word_count = 0\n",
    "    simple_word_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        num_syllables = word_features.get_number_of_syllables(word)\n",
    "        print(word, \"num_syllables:\", num_syllables)\n",
    "        if num_syllables >= 3:\n",
    "            complex_word_count += 1\n",
    "        else:\n",
    "            simple_word_count += 1\n",
    "\n",
    "    return 0.4 * ((len(words) / len(sentences)) + (100 * (complex_word_count / simple_word_count)))\n",
    "\n",
    "def get_record_list(data, all_strings, price_list, all_trigrams, manager_to_unique_interest_levels, building_to_unique_interest_levels, bathrooms_to_unique_interest_levels):\n",
    "    price_bins = get_price_bins(price_list, 5)\n",
    "\n",
    "    features = defaultdict(None)\n",
    "    record_list = []\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    columns = list(data.columns.values)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        features['bathrooms'] = row['bathrooms']\n",
    "        features['bedrooms'] = row['bedrooms']\n",
    "        features['price'] = bin_price(row['price'], price_bins)\n",
    "        features['manager_id'] = row['manager_id']\n",
    "        features['building_id'] = row['building_id']\n",
    "\n",
    "        # uppercase_lowercase_ratio = get_uppercase_lowercase_ratio(row['description'])\n",
    "\n",
    "        # features['uppercase_ratio'] = uppercase_lowercase_ratio['uppercase_ratio']\n",
    "        # features['lowercase_ratio'] = uppercase_lowercase_ratio['lowercase_ratio']\n",
    "\n",
    "        # features['fog_index'] = get_fog_index(row['description'])\n",
    "        \n",
    "        features['completeness_score'] = get_completeness_score(row, columns)\n",
    "\n",
    "        if (len(row['description']) > 0):\n",
    "            features['text_richness'] = len(set(row['description'])) / len(row['description'])\n",
    "        else:\n",
    "            features['text_richness'] = 0\n",
    "        \n",
    "        if (len(manager_to_unique_interest_levels[features['manager_id']]) == 1):\n",
    "            record_list.append((features.copy(), manager_to_unique_interest_levels[features['manager_id']][0]))\n",
    "        else:\n",
    "            record_list.append((features.copy(), row['interest_level']))\n",
    "        \n",
    "        all_features.append(features.copy())\n",
    "        all_labels.append(row['interest_level'])\n",
    "        \n",
    "        if (len(building_to_unique_interest_levels[features['building_id']]) == 1):\n",
    "            record_list.append((features.copy(), building_to_unique_interest_levels[features['building_id']][0]))\n",
    "        else:\n",
    "            record_list.append((features.copy(), row['interest_level']))\n",
    "            \n",
    "        all_features.append(features.copy())\n",
    "        all_labels.append(row['interest_level'])\n",
    "            \n",
    "        if (len(bathrooms_to_unique_interest_levels[features['bathrooms']]) == 1):\n",
    "            record_list.append((features.copy(), bathrooms_to_unique_interest_levels[features['bathrooms']][0]))\n",
    "        else:\n",
    "            record_list.append((features.copy(), row['interest_level']))\n",
    "            \n",
    "        all_features.append(features.copy())\n",
    "        all_labels.append(row['interest_level'])\n",
    "            \n",
    "        features = defaultdict(None)\n",
    "\n",
    "    return record_list, all_features, all_labels\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    manager_to_unique_interest_levels = train_data.groupby('manager_id')[\"interest_level\"].unique().to_dict()\n",
    "    \n",
    "    building_to_unique_interest_levels = train_data.groupby('building_id')[\"interest_level\"].unique().to_dict()\n",
    "    \n",
    "    bathrooms_to_unique_interest_levels = train_data.groupby('bathrooms')[\"interest_level\"].unique().to_dict()\n",
    "\n",
    "    all_strings = []\n",
    "    price_list = []\n",
    "    all_trigrams = set()\n",
    "\n",
    "    for index, row in train_data.iterrows():\n",
    "        price_list.append(row['price'])\n",
    "        strings = [word for word in word_features.clean_html(row[\"description\"].lower()).split(' ') if word not in word_features._stopwords]\n",
    "        all_strings.append(strings.copy())\n",
    "    \n",
    "    record_list, all_features, y = get_record_list(train_data, all_strings, price_list, all_trigrams, manager_to_unique_interest_levels, building_to_unique_interest_levels, bathrooms_to_unique_interest_levels)\n",
    "    \n",
    "    '''\n",
    "    all_strings = []\n",
    "    price_list = []\n",
    "    all_trigrams = set()\n",
    "\n",
    "    for index, row in test_data.iterrows():\n",
    "        price_list.append(row['price'])\n",
    "        strings = [word for word in word_features.clean_html(row[\"description\"].lower()).split(' ') if word not in word_features._stopwords]\n",
    "        all_strings.append(strings.copy())\n",
    "\n",
    "    test_set = get_record_list(test_data, all_strings, price_list, all_trigrams)\n",
    "    '''\n",
    "    \n",
    "    random.shuffle(record_list)\n",
    "    train_set = record_list[(len(record_list)//3):]\n",
    "    test_set = record_list[0:(len(record_list)//3)]\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    X = vec.fit_transform(all_features).toarray()\n",
    "    \n",
    "    X_train = X[(len(X)//3):]\n",
    "    X_test = X[0:(len(X)//3)]\n",
    "\n",
    "    y_train = y[(len(y)//3):]\n",
    "    y_test = y[0:(len(y)//3)]\n",
    "    \n",
    "    print(\"--- generating record_list: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    target = open(\"result.txt\", 'w')\n",
    "\n",
    "    target.truncate()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "    target.write(\"Decision Tree\")\n",
    "    target.write(\"\\n\")\n",
    "    decision_tree_accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    target.write(str(decision_tree_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    print(\"Decision Tree\", decision_tree_accuracy)\n",
    "\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    target.write(\"Naive Bayes\")\n",
    "    target.write(\"\\n\")\n",
    "    naive_bayes_accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    target.write(str(naive_bayes_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "\n",
    "    print(\"Naive Bayes\", naive_bayes_accuracy)\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=20)\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"Random Forest\")\n",
    "    target.write(\"\\n\")\n",
    "    random_forest_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"Random Forest\", classifier.score(X_test, y_test))\n",
    "    target.write(str(random_forest_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = PassiveAggressiveClassifier(loss='squared_hinge', C=1.0)\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"Passive Aggressive\")\n",
    "    target.write(\"\\n\")\n",
    "    passive_aggressive_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"Passive Aggressive Classifier\", passive_aggressive_accuracy)\n",
    "    target.write(str(passive_aggressive_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"K Nearest Neighbors\")\n",
    "    target.write(\"\\n\")\n",
    "    knneighbors_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"K Nearest Neighbors Classifier\", knneighbors_accuracy)\n",
    "    target.write(str(knneighbors_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = SGDClassifier(alpha=.0001, n_iter=50)\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"SGD\")\n",
    "    target.write(\"\\n\")\n",
    "    sgd_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"SGD Classifier\", sgd_accuracy)\n",
    "    target.write(str(sgd_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = Perceptron(n_iter=50)\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"Perceptron\")\n",
    "    target.write(\"\\n\")\n",
    "    perceptron_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"Perceptron\", perceptron_accuracy)\n",
    "    target.write(str(perceptron_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = RidgeClassifier(tol=1e-2, solver=\"lsqr\")\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"Ridge\")\n",
    "    target.write(\"\\n\")\n",
    "    ridge_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"Ridge Classifier\", ridge_accuracy)\n",
    "    target.write(str(ridge_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = NearestCentroid()\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"Nearest Centroid\")\n",
    "    target.write(\"\\n\")\n",
    "    nearest_centroid_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"Nearest Centroid\", nearest_centroid_accuracy)\n",
    "    target.write(str(nearest_centroid_accuracy))\n",
    "    target.write(\"\\n\")\n",
    "    \n",
    "    classifier = BernoulliNB(alpha=.01)\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    target.write(\"BernoulliNB\")\n",
    "    target.write(\"\\n\")\n",
    "    bernoulli_nb_accuracy = classifier.score(X_test, y_test)\n",
    "    print(\"BernoulliNB\", bernoulli_nb_accuracy)\n",
    "    target.write(str(bernoulli_nb_accuracy))\n",
    "    \n",
    "    print(\"--- training/classification: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    target.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
